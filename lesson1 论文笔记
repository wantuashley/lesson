读书笔记：根据语义自动选择字体
题目：
Let Me Choose: From Verbal Context to Font Selection 

实验简介：
在本研究旨在对可视字体属性和文本上下文之间的关联进行建模，最终目标是在文本撰写过程中更好地推荐字体。

实验过程：
该实验中，作者们首先制定一项新任务：“书面文字的字体推荐”。
接着，引入了一个新的短文本字体数据集，该数据集来自Adobe Spark，其中包含各种带有10种不同代表性字体的文本示例，它涵盖了海报，传单，励志名言和广告中的各种主题。
在数据标注阶段，他们要求9个标注员在阅读后选择前三种最合适的字体来标记每个示例文本，为了确保标注员是根据文本的理解而不是个人能力来选择字体。他们删除了90％以上的时间选择相同字体的工作人员的标注。
然后，他们比较了不同的端到端模型，这些模型利用输入文本的上下文和情感表示来推荐字体。通过在训练阶段学习标签分布，这些模型能够抓住所有标注之间的互为主观性（intersubjectivity ）。
最终。证明情感表达可以成功地用来抓住句子的潜在特征以建议适当的字体。

实验任务：
1.任务定义：给定一段文本x，想要确定哪种字体y = {y0，... y9}更适合或与输入文本的属性一致。将此问题表述为排名问题，其中模型为每个字体分配一个实值dxy，代表y描述X的程度。
2.模型：从预先训练的模型中探索迁移学习，以改善任务性能。研究了四种不同的基于深度学习的架构，以了解数据集中的字体分布。
GloVe BiLSTM：我们将编码的单词传递到两个dense layer进行预测。
NRC Model ：LSTM-based的模型，用来自NRC Emotion，Itensity，Valence，Arousal和 Dominance等作为输入
BERT Model ：使用预训练的BERT序列分类模型获得上下文嵌入作为特征。然后将输出反馈到两个密集层，以产生类别预测。
Emoji Model ：使用Deep-Moji预训练模型通过将文本编码为2304维特征向量来生成表情符号向量。将这些特征视为嵌入，并将其传递给具有两个密集层的模型。 
3.结果评估：使用两个不同的评估指标
字体召回（FR） 每种字体的平均召回率，以衡量模型在学习单个标签中的性能
F-score   对于测试集中的每个实例X，我们从地面实况和预测分布中选择概率最高的前k = {1、3和5}个字体。然后，我们为每个k计算加权平均F1分数。

实验结果：
与多数基准相比，Emoji和BERT模型的结果在配对t检验下具有95％的置信区间，具有统计学意义。尽管BERT模型的性能略好于其他模型，但Emoji模型的性能也一样，这表明了两件事：
（1）字体推荐任务与表情符号代表的高度相关； 
（2）较简单的模型（例如Emoji模型）可以类似地执行到像BERT这样的复杂解决方案。

结论：
实验者将字体与书面文本相关联，并从输入文本中解决了字体推荐问题。他们收集了1,300多个简短的书面文本，并用十种字体对其进行了注释。实验将该任务表述为排名问题，并基于情感和上下文表示对不同模型进行了比较，这些表示利用标签分布学习来预测字体。
该结论还可以扩展以支持更大的字体集。例如，可以使用字体相似性技术，使用户能够选择一组字体，或者为用户可用的字体提供更大的灵活性。
